# ğŸ§  Conception â€” Arquitetura e DecisÃµes TÃ©cnicas do Sistema de Agentes

**Metadados do Documento:**
- **VersÃ£o:** 1.2
- **Data de AtualizaÃ§Ã£o:** 2025-01-25
- **Autor:** StatesMedia Team
- **Tipo:** DocumentaÃ§Ã£o TÃ©cnica de Arquitetura

---

## 1. Escolha do LLM

O sistema utiliza dois modelos de linguagem principais: **GPT-5-mini** (modelo primÃ¡rio) e **GPT-4.1-mini** (fallback).

### GPT-5-mini (principal)

Ã‰ o modelo padrÃ£o para a maioria das tarefas de raciocÃ­nio, geraÃ§Ã£o e anÃ¡lise. Foi configurado com **reasoning effort = low**, garantindo **baixa latÃªncia**, **menor custo por requisiÃ§Ã£o** e Ã³timo equilÃ­brio entre contexto e coerÃªncia textual.

Sua janela de contexto de **30.000 tokens** permite processar PDFs extensos sem fragmentaÃ§Ã£o excessiva. Ele foi escolhido por oferecer o melhor **custo-benefÃ­cio** entre profundidade analÃ­tica e tempo de resposta, sendo ideal para os agentes **Engenheiro de Big Idea**, **Estrategista de OtimizaÃ§Ã£o** e **Avaliador E5**.

### GPT-4.1-mini (fallback)

Atua como reserva automÃ¡tica quando hÃ¡ saturaÃ§Ã£o de chamadas ou necessidade de dupla validaÃ§Ã£o semÃ¢ntica. O modelo se destaca pelo balanceamento entre **custo, velocidade e qualidade de instruÃ§Ã£o**, oferecendo alta confiabilidade e respostas consistentes em fluxos crÃ­ticos (como os agentes **CrÃ­tico de AprovaÃ§Ã£o** e **Orquestrador**).

Seu comportamento previsÃ­vel e estÃ¡vel Ã© essencial para manter a coerÃªncia entre as etapas de anÃ¡lise e sÃ­ntese do JSON final.

Essa combinaÃ§Ã£o de LLMs proporciona **redundÃ¢ncia inteligente** e **otimizaÃ§Ã£o de custos**, mantendo o desempenho consistente mesmo em execuÃ§Ãµes paralelas no n8n.

---

## 2. Escolha da Base de Dados Vetorial

A base de conhecimento utiliza **Supabase com extensÃ£o pgvector**.

### Justificativas tÃ©cnicas:

- **IntegraÃ§Ã£o nativa com PostgreSQL**, facilitando a execuÃ§Ã£o de queries hÃ­bridas entre dados estruturados e embeddings vetoriais.
- Suporte Ã  funÃ§Ã£o **ai_match_documents**, que realiza busca semÃ¢ntica direta e eficiente, sem dependÃªncia de serviÃ§os externos.
- **SeguranÃ§a reforÃ§ada via Row Level Security (RLS)** e autenticaÃ§Ã£o nativa da Supabase.
- **Compatibilidade total com fluxos automatizados do n8n**, permitindo consultas SQL ou REST em tempo real.
- **Custos previsÃ­veis e escalabilidade horizontal** â€” diferentemente de alternativas como Pinecone (custo variÃ¡vel) ou ChromaDB (persistÃªncia limitada).

---

## 3. Arquitetura Geral â€” Fluxo de Dados

O sistema adota uma **arquitetura multiagente orquestrada via n8n**, com fluxo linear e pontos de iteraÃ§Ã£o entre os agentes cognitivos.

```
UsuÃ¡rio â†’ Upload/Link PDF â†’ ExtraÃ§Ã£o (n8n) â†’ VetorizaÃ§Ã£o (Supabase) â†’ 
Agentes (GPT-5-mini / 4.1-mini) â†’ SÃ­ntese JSON â†’ Supabase
```

### Etapas Detalhadas

#### RecepÃ§Ã£o do briefing (PDF)
O arquivo Ã© baixado via **HTTP** (se for link do Google Drive) ou enviado diretamente pela **interface**.
O nÃ³ **"Extract PDF"** converte o conteÃºdo em texto bruto e metadados (tÃ­tulo, tÃ³picos, sumÃ¡rio, etc.).

#### PrÃ©-processamento
O texto Ã© normalizado, tokenizado e dividido em blocos de atÃ© **30.000 tokens**, compatÃ­veis com o limite do GPT-5-mini.
Os trechos sÃ£o entÃ£o vetorizados e armazenados na Supabase.

#### DistribuiÃ§Ã£o entre Agentes
- **Orquestrador:** centraliza o fluxo, gerencia chamadas e consolida resultados.
- **Engenheiro de Big Idea:** identifica o conceito-nÃºcleo e traduz a intenÃ§Ã£o estratÃ©gica.
- **Estrategista de OtimizaÃ§Ã£o:** refina estrutura, adiciona mÃ©tricas e melhora legibilidade.
- **CrÃ­tico de AprovaÃ§Ã£o:** realiza a revisÃ£o tÃ©cnica, coerÃªncia textual e aderÃªncia ao padrÃ£o.
- **Avaliador E5:** aplica a matriz de avaliaÃ§Ã£o (EficiÃªncia, Estilo, EstratÃ©gia, Estrutura e EspÃ­rito).

#### Consulta Ã  Base Vetorial (RAG)
Cada agente consulta a Supabase via funÃ§Ã£o **match_documents**, que retorna os trechos mais semanticamente relevantes.
Os resultados sÃ£o inseridos no **prompt context** de cada agente, aprimorando precisÃ£o e contextualizaÃ§Ã£o.

#### FusÃ£o dos Resultados
As respostas dos agentes sÃ£o retornadas ao **Orquestrador**, que:
- Verifica coerÃªncia e sobreposiÃ§Ã£o de ideias.
- Resolve divergÃªncias.
- Consolida tudo em um **JSON final padronizado** com campos:

```json
{
  "big_idea": "...",
  "otimizacao": "...",
  "critica": "...",
  "avaliacao_e5": "..."
}
```

O JSON Ã© armazenado na Supabase e disponibilizado via API ou dashboard.

---

## 4. Stack Resumida

| Camada | Tecnologia | FunÃ§Ã£o Principal |
|--------|------------|------------------|
| **Entrada** | HTTP / Google Drive API | RecepÃ§Ã£o do briefing |
| **Processamento** | n8n Extract PDF | ConversÃ£o de PDF em texto |
| **VetorizaÃ§Ã£o** | Supabase + pgvector | Armazenamento semÃ¢ntico |
| **Agentes** | GPT-5-mini (low reasoning), GPT-4.1-mini (fallback) | RaciocÃ­nio e anÃ¡lise |
| **OrquestraÃ§Ã£o** | n8n | Controle de fluxo entre agentes |
| **PersistÃªncia** | Supabase PostgreSQL | Armazenamento de resultados |
| **SaÃ­da** | JSON estruturado | IntegraÃ§Ã£o com painÃ©is e relatÃ³rios |

---

## 5. ConclusÃ£o

A arquitetura privilegia **eficiÃªncia, resiliÃªncia e escalabilidade**.

O uso do **GPT-5-mini** como agente principal garante respostas rÃ¡pidas e coerentes com baixo custo computacional, enquanto o **GPT-4.1-mini** oferece redundÃ¢ncia e estabilidade em cenÃ¡rios crÃ­ticos.

A integraÃ§Ã£o com **Supabase** fornece um backend vetorial unificado, simplificando o RAG e permitindo rastreabilidade completa dos dados.

O resultado Ã© um **ecossistema de agentes modular, auditÃ¡vel e economicamente otimizado**, ideal para aplicaÃ§Ãµes de anÃ¡lise automatizada de documentos.

# ğŸ§  DocumentaÃ§Ã£o de Engenharia de Prompt â€” Sistema Todd Brown AI Framework

## ğŸ“˜ 1. VisÃ£o Geral

O **Todd Brown AI Framework** Ã© um sistema multiagente desenvolvido para analisar, avaliar e otimizar campanhas de VSLs (Video Sales Letters) com base na metodologia original de **Todd Brown**.  
Cada agente representa uma faceta especÃ­fica do raciocÃ­nio estratÃ©gico do autor â€” e todos compartilham uma mesma engenharia de prompt cognitiva.  

Os quatro agentes principais sÃ£o:

- ğŸ§© **CrÃ­tico de AprovaÃ§Ã£o** â†’ Valida estrutura e estratÃ©gia conforme o princÃ­pio 75/25 e frameworks de fundaÃ§Ã£o.  
- ğŸ’¡ **Engenheiro de Big Idea** â†’ Extrai, disseca e melhora a Grande Ideia de Marketing (BMI).  
- ğŸ“Š **Avaliador E5** â†’ Mede e justifica a eficÃ¡cia de cada bloco da VSL (Lead, HistÃ³ria, Mecanismo, Oferta).  
- âš™ï¸ **Estrategista de OtimizaÃ§Ã£o** â†’ Sintetiza as anÃ¡lises e propÃµe ajustes para conversÃ£o mÃ¡xima.

Todos foram construÃ­dos sobre o mesmo nÃºcleo de engenharia: **Cognitive Protocol Prompting**, combinando raciocÃ­nio controlado, recuperaÃ§Ã£o semÃ¢ntica (RAG) e saÃ­das determinÃ­sticas em JSON.

---

## âš™ï¸ 2. Paradigma de Engenharia de Prompt

A arquitetura segue o modelo **Cognitive Protocol Prompting**, no qual cada agente Ã© instruÃ­do nÃ£o apenas sobre *o que fazer*, mas **como pensar passo a passo**.  
Em vez de respostas improvisadas, os prompts impÃµem uma sequÃªncia lÃ³gica de raciocÃ­nio, baseada em trÃªs princÃ­pios:

1. **RAG Anchoring** â€” toda decisÃ£o Ã© embasada em uma fonte real (â€œEssÃªncia MetodolÃ³gica de Todd Brown para VSLs.docxâ€).  
2. **Chain of Thought Controlado** â€” o raciocÃ­nio interno Ã© explicitamente registrado com a ferramenta `think_tool()`.  
3. **SaÃ­da DeterminÃ­stica** â€” todos os agentes retornam JSON padronizado, auditÃ¡vel e legÃ­vel por mÃ¡quina.

Esse paradigma cria um comportamento cognitivo coerente e previsÃ­vel, transformando modelos de linguagem em **avaliadores estratÃ©gicos explicÃ¡veis**.

---

## ğŸ§© 3. Pipeline Cognitivo Compartilhado

Todos os agentes seguem um mesmo fluxo de raciocÃ­nio, independentemente da tarefa:

| Etapa | DescriÃ§Ã£o | Ferramenta |
|-------|------------|-------------|
| **1. Entrada** | Recebe o briefing completo da VSL. | â€” |
| **2. RecuperaÃ§Ã£o de PrincÃ­pios** | Busca conceitos e frameworks relevantes na base vetorial. | `fonte()` |
| **3. AnÃ¡lise Cognitiva** | Compara briefing com princÃ­pios e estrutura ideal. | `think_tool()` |
| **4. SÃ­ntese EstratÃ©gica** | Produz decisÃ£o, avaliaÃ§Ã£o ou plano de melhoria. | `think_tool()` |
| **5. SaÃ­da Padronizada** | Retorna JSON estruturado (decisÃ£o, notas, justificativas). | â€” |

Essa estrutura garante que todos os agentes â€œpensem do mesmo jeitoâ€ â€” e que suas respostas possam ser integradas automaticamente em um pipeline analÃ­tico.

---

## ğŸ§  4. FunÃ§Ã£o e ImportÃ¢ncia da `think_tool()`

A **`think_tool()`** Ã© o coraÃ§Ã£o cognitivo do sistema.  
Ela obriga o modelo a **registrar o raciocÃ­nio antes de gerar a resposta**, garantindo transparÃªncia e coerÃªncia.

### âœ³ï¸ FunÃ§Ãµes Principais:

1. **ForÃ§ar RaciocÃ­nio Sequencial:**  
   Nenhuma conclusÃ£o Ã© permitida sem que o modelo explique o passo anterior.

2. **Simular Pensamento CrÃ­tico:**  
   Cada agente age como um especialista que pensa, compara e decide com base em critÃ©rios claros.

3. **Evitar AlucinaÃ§Ã£o:**  
   O uso conjunto da `think_tool()` com a `fonte()` obriga a IA a citar princÃ­pios reais da base, reduzindo invenÃ§Ãµes.

4. **Rastreabilidade:**  
   Permite auditar o â€œrastro mentalâ€ do modelo â€” crucial para avaliar consistÃªncia em execuÃ§Ãµes mÃºltiplas.

5. **Reprodutibilidade:**  
   O mesmo input gera o mesmo raciocÃ­nio e resultado, garantindo estabilidade e confiabilidade em escala.

> ğŸ” Em termos tÃ©cnicos, a `think_tool()` converte raciocÃ­nio implÃ­cito em **razÃ£o auditÃ¡vel**, transformando o LLM em um agente de decisÃ£o explicÃ¡vel.

---

## ğŸ“š 5. FunÃ§Ã£o da `fonte()` (Base de Conhecimento RAG)

A ferramenta **`fonte()`** conecta todos os agentes Ã  base vetorial construÃ­da a partir do documento  
**â€œEssÃªncia MetodolÃ³gica de Todd Brown para VSLs.docxâ€**, elaborado via **Gemini Deep Research**.  

Essa base contÃ©m princÃ­pios fundamentais, frameworks (E5, 75/25, Big Idea, Unique Mechanism), armadilhas comuns e exemplos anotados.  
Ela Ã© estruturada em chunks semÃ¢nticos com `metadata JSONB` contendo campos como:

- `category` (ex: BIG_IDEA, FUNDAMENTOS, ESTRUTURA_VSL)  
- `subcategory` (ex: lead, historia, mecanismo, oferta)  
- `concept` (ex: principio_75_25, mecanismo_integrado, armadilha_commodity)  
- `negative_example` (ex: true para erros e falhas)  

### Exemplo de chamada:
```bash
fonte(query="FunÃ§Ã£o e critÃ©rios de um Lead eficaz em VSL", filter={"category": "ESTRUTURA_VSL"})
A fonte() garante consistÃªncia epistemolÃ³gica â€” toda resposta Ã© ancorada em conhecimento real e verificÃ¡vel.

ğŸ§± 6. SaÃ­das Estruturadas e InteroperÃ¡veis
Os quatro agentes retornam respostas 100% estruturadas em JSON, ideais para ingestÃ£o por ferramentas como n8n, Supabase, Bubble e Retool.

Agente	Estrutura de SaÃ­da
ğŸ§© CrÃ­tico de AprovaÃ§Ã£o	{ "todd_brown_approval": { "approved": bool, "framework_correct": bool, "justification": str } }
ğŸ’¡ Engenheiro de Big Idea	{ "extracted_idea": str, "improvements": [ { "point": str, "justification": str } Ã— 5 ] }
ğŸ“Š Avaliador E5	[ { "section": str, "score": int, "justification": str } Ã— 4 ]
âš™ï¸ Estrategista de OtimizaÃ§Ã£o	{ "optimization_plan": [ { "aspect": str, "action": str, "rationale": str } Ã— n ] }

Esse formato facilita comparaÃ§Ãµes, rankings, dashboards e visualizaÃ§Ãµes em BI.

ğŸ§¬ 7. BenefÃ­cios da Engenharia Unificada
BenefÃ­cio	DescriÃ§Ã£o
CoerÃªncia entre agentes	Todos compartilham o mesmo protocolo cognitivo e base RAG.
Escalabilidade	Pode processar dezenas de campanhas simultaneamente.
Auditabilidade total	Cada decisÃ£o tem registro de raciocÃ­nio via think_tool().
Reprodutibilidade	SaÃ­das determinÃ­sticas sob mesmas condiÃ§Ãµes de entrada.
TransparÃªncia e explicabilidade	O raciocÃ­nio Ã© exposto e pode ser revisado humanamente.
ReduÃ§Ã£o de custo	Modelos pequenos (GPT-5 mini, GPT-4.1 mini) garantem eficiÃªncia sem perder rigor.

âš™ï¸ 8. EspecificaÃ§Ãµes TÃ©cnicas
ParÃ¢metro	Valor
Paradigma de Prompt	Cognitive Protocol Prompting
Modelo Principal	GPT-5 mini (Reasoning Effort: Low)
Fallback	GPT-4.1 mini
Janela de Contexto	~30 000 tokens
Base RAG	â€œEssÃªncia MetodolÃ³gica de Todd Brown para VSLs.docxâ€ (Gemini Deep Research)
Ferramentas Cognitivas	think_tool() e fonte()
Linguagem	PortuguÃªs do Brasil
SaÃ­da	JSON estruturado e determinÃ­stico
Compatibilidade	n8n â€¢ Supabase â€¢ Bubble â€¢ Retool â€¢ Data Studio

ğŸ’¡ 9. ConclusÃ£o
A arquitetura de engenharia de prompt dos quatro agentes Todd Brown Ã© um exemplo de IA cognitiva aplicada a copywriting estratÃ©gico.
Cada agente pensa, consulta e decide como um especialista humano â€” mas com rastreabilidade e consistÃªncia algorÃ­tmica.

A combinaÃ§Ã£o de think_tool() e fonte() cria um equilÃ­brio perfeito entre raciocÃ­nio e referÃªncia:
a primeira garante pensamento lÃ³gico e explicÃ¡vel; a segunda garante fundamentaÃ§Ã£o real nos princÃ­pios da metodologia.

ğŸ” Em suma, o sistema Todd Brown AI transforma LLMs em avaliadores estratÃ©gicos explicÃ¡veis, capazes de raciocinar com base em frameworks e entregar anÃ¡lises estruturadas, confiÃ¡veis e auditÃ¡veis â€” elevando o nÃ­vel da automaÃ§Ã£o em marketing de performance.